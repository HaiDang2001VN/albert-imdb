{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k2Sz8fHdasgl","outputId":"b11d4a49-361a-4d0e-e676-f4e8f0e275e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'source'...\n","remote: Enumerating objects: 224, done.\u001b[K\n","remote: Counting objects: 100% (224/224), done.\u001b[K\n","remote: Compressing objects: 100% (108/108), done.\u001b[K\n","remote: Total 224 (delta 116), reused 217 (delta 111), pack-reused 0\u001b[K\n","Receiving objects: 100% (224/224), 2.52 MiB | 8.36 MiB/s, done.\n","Resolving deltas: 100% (116/116), done.\n","Collecting wandb\n","  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Collecting transformers\n","  Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n","Collecting huggingface_hub\n","  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate\n","  Downloading accelerate-0.29.1-py3-none-any.whl (297 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.3/297.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-1.44.1-py2.py3-none-any.whl (266 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Collecting datasets>=2.0.0 (from evaluate)\n","  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill (from evaluate)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n","Collecting xxhash (from evaluate)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from evaluate)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Collecting responses<0.19 (from evaluate)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.10.0)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/166.0 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:11\u001b[0m"]}],"source":["if True:\n","    %rm -rf source\n","    !git clone https://github.com/HaiDang2001VN/albert-imdb.git source\n","    %pip install -U wandb transformers evaluate huggingface_hub accelerate\n","    colab = True\n","else:\n","    print(\"Not running on Google Colab, skip this cell!\")\n","    colab = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qsm8c6uKafOI"},"outputs":[],"source":["import json\n","from pprint import pprint\n","\n","# Load path to pre-processed data in configs folder\n","config_file = \"vlsp_colab\" if colab else \"vlsp_local\"\n","with open(f\"configs/{config_file}.json\") as f:\n","    configs = json.load(f)\n","\n","pprint(configs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1aJJXeTTafOG"},"outputs":[],"source":["import wandb\n","\n","run_model = [\"phobert\", \"base\", \"format0\"]\n","wandb.init(project=\"advanced_ai_imdb_dataset\", name=f\"{run_model[0]}-{run_model[1]}-run-vlsp-{run_model[2]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8WCMRmKoafOJ"},"outputs":[],"source":["from datasets import load_dataset\n","\n","source_path = configs[\"path\"]\n","format_name = run_model[2]\n","# format_name = \"format1\"\n","# train_set = load_dataset(\n","#     \"json\", data_files=f\"./vlsp_preprocessed/{format_name}/train.jsonl\", split=\"train\"\n","# )\n","# val_set = load_dataset(\n","#     \"json\", data_files=f\"./vlsp_preprocessed/{format_name}/dev.jsonl\", split=\"train\"\n","# )\n","# test_set = load_dataset(\n","#     \"json\", data_files=f\"./vlsp_preprocessed/{format_name}/test.jsonl\", split=\"train\"\n","# )\n","dataset = load_dataset(\n","    \"json\",\n","    data_files={\n","        \"train\": f\"{source_path}/vlsp_preprocessed/{format_name}/train.jsonl\",\n","        \"val\": f\"{source_path}/vlsp_preprocessed/{format_name}/dev.jsonl\",\n","        \"test\": f\"{source_path}/vlsp_preprocessed/{format_name}/test.jsonl\",\n","    },\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KMkdfZYaUGLs"},"outputs":[],"source":["model_path = configs['model_path'][run_model[0]][run_model[1]]\n","print(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ByDF0YD7afOJ"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForSequenceClassification.from_pretrained(model_path,\n","                                                           num_labels=4,\n","                                                           output_hidden_states=False\n","                                                           )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LETnyCsrafOJ"},"outputs":[],"source":["def preprocess_token(example):\n","    return tokenizer(\n","        example[\"sentence\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lp6gso3kafOJ"},"outputs":[],"source":["tokenized_dataset = dataset.map(preprocess_token, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nqnx2ENDafOK"},"outputs":[],"source":["from transformers import DataCollatorWithPadding\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VfaLmYLVafOK"},"outputs":[],"source":["import evaluate\n","\n","accuracy = evaluate.load(\"accuracy\")\n","f1 = evaluate.load(\"f1\")\n","precision = evaluate.load(\"precision\")\n","recall = evaluate.load(\"recall\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U5GvdgOjafOK"},"outputs":[],"source":["import numpy as np\n","\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    print(f\"Type of {type(predictions)=}\")\n","    print(f\"Type of {type(labels)=}\")\n","    print(f\"Shape of {predictions[0].shape}\")\n","    print(f\"Shape of {predictions[1].shape}\")\n","    if isinstance(predictions, tuple):\n","        predictions = predictions[0]\n","    predictions = np.argmax(predictions, axis=1)\n","    # predictions = np.argmax(predictions.reshape(-1, predictions.shape[-1]), axis=1)\n","    return {\n","        \"accuracy\": accuracy.compute(predictions=predictions, references=labels)['accuracy'],\n","        \"f1_macro\": f1.compute(predictions=predictions, references=labels, average=\"macro\")['f1'],\n","        \"f1_micro\": f1.compute(predictions=predictions, references=labels, average=\"micro\")['f1'],\n","        \"f1_weighted\": f1.compute(predictions=predictions, references=labels, average=\"weighted\")['f1'],\n","        \"precision_macro\": precision.compute(predictions=predictions, references=labels, average=\"macro\")['precision'],\n","        \"precision_micro\": precision.compute(predictions=predictions, references=labels, average=\"micro\")['precision'],\n","        \"precision_weighted\": precision.compute(predictions=predictions, references=labels, average=\"weighted\")['precision'],\n","        \"recall_macro\": recall.compute(predictions=predictions, references=labels, average=\"macro\")['recall'],\n","        \"recall_micro\": recall.compute(predictions=predictions, references=labels, average=\"micro\")['recall'],\n","        \"recall_weighted\": recall.compute(predictions=predictions, references=labels, average=\"weighted\")['recall'],\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1711462847381,"user":{"displayName":"Đăng Huỳnh Lâm Hải","userId":"13564525226852980347"},"user_tz":-420},"id":"ZIGiAMKvafOK","outputId":"3d831d20-472b-4f1e-998f-486902b2d99d"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'AFFILIATION': 0, 'PART – WHOLE': 1, 'LOCATED': 2, 'PERSONAL - SOCIAL': 3}\n"]}],"source":["id2label = {0: 'AFFILIATION', 1: 'PART – WHOLE', 2: 'LOCATED', 3: 'PERSONAL - SOCIAL'}\n","label2id = {value: key for key, value in id2label.items()}\n","print(label2id)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":598,"status":"ok","timestamp":1711462847974,"user":{"displayName":"Đăng Huỳnh Lâm Hải","userId":"13564525226852980347"},"user_tz":-420},"id":"TzDkIlrKafOL","outputId":"83efcec8-f120-417b-e78c-52463be34fb7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]}],"source":["from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n","\n","training_args = TrainingArguments(\n","    output_dir=\"albert_imdb\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=25,\n","    weight_decay=0.01,\n","    save_steps=0.1,\n","    load_best_model_at_end=True,\n","    overwrite_output_dir=True,\n","    save_total_limit=1,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=0.1,\n","    logging_steps=0.05,\n","    report_to=\"wandb\",\n","    gradient_accumulation_steps=5,\n","    # push_to_hub=True,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"val\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1711462847974,"user":{"displayName":"Đăng Huỳnh Lâm Hải","userId":"13564525226852980347"},"user_tz":-420},"id":"r7dEI8kaafOL","outputId":"e7257e73-7a61-4f2b-df99-9dc9d3a16d22"},"outputs":[{"data":{"text/plain":["{'sentence': 'Trong ảnh : Nghệ_thuật tạo hoa_văn trên trang_phục truyền_thống của người Mông hoa , tại <location> xã Sa_Lông </location> , <location> huyện Mường_Chà </location> .',\n"," 'label': 2,\n"," 'input_ids': [2,\n","  13,\n","  38,\n","  14271,\n","  40,\n","  252,\n","  13,\n","  45,\n","  13,\n","  2723,\n","  438,\n","  1,\n","  38,\n","  7325,\n","  38,\n","  14341,\n","  20538,\n","  1,\n","  2686,\n","  26407,\n","  13,\n","  38,\n","  13119,\n","  1,\n","  3971,\n","  6335,\n","  8600,\n","  8944,\n","  1,\n","  96,\n","  3279,\n","  13,\n","  22936,\n","  13,\n","  2723,\n","  13324,\n","  49,\n","  21028,\n","  20538,\n","  13,\n","  15,\n","  5466,\n","  13,\n","  1,\n","  19032,\n","  1,\n","  13,\n","  6791,\n","  1929,\n","  1,\n","  2701,\n","  13,\n","  1,\n","  118,\n","  19032,\n","  1,\n","  13,\n","  15,\n","  13,\n","  1,\n","  19032,\n","  1,\n","  4429,\n","  8944,\n","  2832,\n","  3279,\n","  1,\n","  1651,\n","  13,\n","  1,\n","  118,\n","  19032,\n","  1,\n","  13,\n","  9,\n","  3,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0],\n"," 'token_type_ids': [0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0],\n"," 'attention_mask': [1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0]}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_dataset[\"train\"][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":810073,"status":"ok","timestamp":1711466360918,"user":{"displayName":"Đăng Huỳnh Lâm Hải","userId":"13564525226852980347"},"user_tz":-420},"id":"HjJ_jL6IafOL","outputId":"51988215-04f6-4a19-d3e6-e641bb2ee91c"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='341' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [341/625 44:49 < 37:33, 0.13 it/s, Epoch 13.60/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 Macro</th>\n","      <th>F1 Micro</th>\n","      <th>F1 Weighted</th>\n","      <th>Precision Macro</th>\n","      <th>Precision Micro</th>\n","      <th>Precision Weighted</th>\n","      <th>Recall Macro</th>\n","      <th>Recall Micro</th>\n","      <th>Recall Weighted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>63</td>\n","      <td>1.097500</td>\n","      <td>0.475202</td>\n","      <td>0.841402</td>\n","      <td>0.866019</td>\n","      <td>0.841402</td>\n","      <td>0.843592</td>\n","      <td>0.871212</td>\n","      <td>0.841402</td>\n","      <td>0.851553</td>\n","      <td>0.865719</td>\n","      <td>0.841402</td>\n","      <td>0.841402</td>\n","    </tr>\n","    <tr>\n","      <td>126</td>\n","      <td>0.383900</td>\n","      <td>0.432957</td>\n","      <td>0.814691</td>\n","      <td>0.818625</td>\n","      <td>0.814691</td>\n","      <td>0.812231</td>\n","      <td>0.860568</td>\n","      <td>0.814691</td>\n","      <td>0.825216</td>\n","      <td>0.791536</td>\n","      <td>0.814691</td>\n","      <td>0.814691</td>\n","    </tr>\n","    <tr>\n","      <td>189</td>\n","      <td>0.281800</td>\n","      <td>0.308675</td>\n","      <td>0.879800</td>\n","      <td>0.896656</td>\n","      <td>0.879800</td>\n","      <td>0.879280</td>\n","      <td>0.902773</td>\n","      <td>0.879800</td>\n","      <td>0.881063</td>\n","      <td>0.892207</td>\n","      <td>0.879800</td>\n","      <td>0.879800</td>\n","    </tr>\n","    <tr>\n","      <td>252</td>\n","      <td>0.200400</td>\n","      <td>0.277068</td>\n","      <td>0.898164</td>\n","      <td>0.912240</td>\n","      <td>0.898164</td>\n","      <td>0.897111</td>\n","      <td>0.921658</td>\n","      <td>0.898164</td>\n","      <td>0.899484</td>\n","      <td>0.905633</td>\n","      <td>0.898164</td>\n","      <td>0.898164</td>\n","    </tr>\n","    <tr>\n","      <td>315</td>\n","      <td>0.135200</td>\n","      <td>0.308870</td>\n","      <td>0.894825</td>\n","      <td>0.910360</td>\n","      <td>0.894825</td>\n","      <td>0.894403</td>\n","      <td>0.917921</td>\n","      <td>0.894825</td>\n","      <td>0.897033</td>\n","      <td>0.905019</td>\n","      <td>0.894825</td>\n","      <td>0.894825</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Type of type(predictions)=<class 'numpy.ndarray'>\n","Type of type(labels)=<class 'numpy.ndarray'>\n","Shape of (4,)\n","Shape of (4,)\n","Type of type(predictions)=<class 'numpy.ndarray'>\n","Type of type(labels)=<class 'numpy.ndarray'>\n","Shape of (4,)\n","Shape of (4,)\n","Type of type(predictions)=<class 'numpy.ndarray'>\n","Type of type(labels)=<class 'numpy.ndarray'>\n","Shape of (4,)\n","Shape of (4,)\n","Type of type(predictions)=<class 'numpy.ndarray'>\n","Type of type(labels)=<class 'numpy.ndarray'>\n","Shape of (4,)\n","Shape of (4,)\n","Type of type(predictions)=<class 'numpy.ndarray'>\n","Type of type(labels)=<class 'numpy.ndarray'>\n","Shape of (4,)\n","Shape of (4,)\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='441' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [441/625 58:22 < 24:27, 0.13 it/s, Epoch 17/25]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 Macro</th>\n","      <th>F1 Micro</th>\n","      <th>F1 Weighted</th>\n","      <th>Precision Macro</th>\n","      <th>Precision Micro</th>\n","      <th>Precision Weighted</th>\n","      <th>Recall Macro</th>\n","      <th>Recall Micro</th>\n","      <th>Recall Weighted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>63</td>\n","      <td>1.097500</td>\n","      <td>0.475202</td>\n","      <td>0.841402</td>\n","      <td>0.866019</td>\n","      <td>0.841402</td>\n","      <td>0.843592</td>\n","      <td>0.871212</td>\n","      <td>0.841402</td>\n","      <td>0.851553</td>\n","      <td>0.865719</td>\n","      <td>0.841402</td>\n","      <td>0.841402</td>\n","    </tr>\n","    <tr>\n","      <td>126</td>\n","      <td>0.383900</td>\n","      <td>0.432957</td>\n","      <td>0.814691</td>\n","      <td>0.818625</td>\n","      <td>0.814691</td>\n","      <td>0.812231</td>\n","      <td>0.860568</td>\n","      <td>0.814691</td>\n","      <td>0.825216</td>\n","      <td>0.791536</td>\n","      <td>0.814691</td>\n","      <td>0.814691</td>\n","    </tr>\n","    <tr>\n","      <td>189</td>\n","      <td>0.281800</td>\n","      <td>0.308675</td>\n","      <td>0.879800</td>\n","      <td>0.896656</td>\n","      <td>0.879800</td>\n","      <td>0.879280</td>\n","      <td>0.902773</td>\n","      <td>0.879800</td>\n","      <td>0.881063</td>\n","      <td>0.892207</td>\n","      <td>0.879800</td>\n","      <td>0.879800</td>\n","    </tr>\n","    <tr>\n","      <td>252</td>\n","      <td>0.200400</td>\n","      <td>0.277068</td>\n","      <td>0.898164</td>\n","      <td>0.912240</td>\n","      <td>0.898164</td>\n","      <td>0.897111</td>\n","      <td>0.921658</td>\n","      <td>0.898164</td>\n","      <td>0.899484</td>\n","      <td>0.905633</td>\n","      <td>0.898164</td>\n","      <td>0.898164</td>\n","    </tr>\n","    <tr>\n","      <td>315</td>\n","      <td>0.135200</td>\n","      <td>0.308870</td>\n","      <td>0.894825</td>\n","      <td>0.910360</td>\n","      <td>0.894825</td>\n","      <td>0.894403</td>\n","      <td>0.917921</td>\n","      <td>0.894825</td>\n","      <td>0.897033</td>\n","      <td>0.905019</td>\n","      <td>0.894825</td>\n","      <td>0.894825</td>\n","    </tr>\n","    <tr>\n","      <td>378</td>\n","      <td>0.108200</td>\n","      <td>0.332039</td>\n","      <td>0.894825</td>\n","      <td>0.910134</td>\n","      <td>0.894825</td>\n","      <td>0.894178</td>\n","      <td>0.916722</td>\n","      <td>0.894825</td>\n","      <td>0.895615</td>\n","      <td>0.905161</td>\n","      <td>0.894825</td>\n","      <td>0.894825</td>\n","    </tr>\n","    <tr>\n","      <td>441</td>\n","      <td>0.081900</td>\n","      <td>0.373421</td>\n","      <td>0.891486</td>\n","      <td>0.907656</td>\n","      <td>0.891486</td>\n","      <td>0.891693</td>\n","      <td>0.911070</td>\n","      <td>0.891486</td>\n","      <td>0.893316</td>\n","      <td>0.905254</td>\n","      <td>0.891486</td>\n","      <td>0.891486</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Type of type(predictions)=<class 'numpy.ndarray'>\n","Type of type(labels)=<class 'numpy.ndarray'>\n","Shape of (4,)\n","Shape of (4,)\n","Type of type(predictions)=<class 'numpy.ndarray'>\n","Type of type(labels)=<class 'numpy.ndarray'>\n","Shape of (4,)\n","Shape of (4,)\n"]},{"data":{"text/plain":["TrainOutput(global_step=441, training_loss=0.27899570827311126, metrics={'train_runtime': 3511.8255, 'train_samples_per_second': 14.238, 'train_steps_per_second': 0.178, 'total_flos': 843291718778880.0, 'train_loss': 0.27899570827311126, 'epoch': 17.64})"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":376},"executionInfo":{"elapsed":21767,"status":"ok","timestamp":1711466382681,"user":{"displayName":"Đăng Huỳnh Lâm Hải","userId":"13564525226852980347"},"user_tz":-420},"id":"PAtVa-u9lVYf","outputId":"c66250f1-679d-4cc6-c456-fd66e13f48b3"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [38/38 00:21]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Type of type(predictions)=<class 'numpy.ndarray'>\n","Type of type(labels)=<class 'numpy.ndarray'>\n","Shape of (4,)\n","Shape of (4,)\n"]},{"data":{"text/plain":["{'eval_loss': 0.27706798911094666,\n"," 'eval_accuracy': 0.8981636060100167,\n"," 'eval_f1_macro': 0.9122397640750749,\n"," 'eval_f1_micro': 0.8981636060100167,\n"," 'eval_f1_weighted': 0.8971114223634937,\n"," 'eval_precision_macro': 0.9216578612895938,\n"," 'eval_precision_micro': 0.8981636060100167,\n"," 'eval_precision_weighted': 0.8994842983190149,\n"," 'eval_recall_macro': 0.9056329585751128,\n"," 'eval_recall_micro': 0.8981636060100167,\n"," 'eval_recall_weighted': 0.8981636060100167,\n"," 'eval_runtime': 22.2396,\n"," 'eval_samples_per_second': 26.934,\n"," 'eval_steps_per_second': 1.709,\n"," 'epoch': 17.64}"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f_eUC-cNTyfO"},"outputs":[],"source":["trainer.evaluate(tokenized_dataset[\"test\"], metric_key_prefix=\"test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VzBSgGyi0CPw"},"outputs":[],"source":["predictions = trainer.predict(tokenized_dataset[\"test\"]).label_ids\n","print(predictions.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nw9zDs-C0CPw"},"outputs":[],"source":["# Showing the sentence, label and predicted label\n","for i in range(10):\n","    print(tokenized_dataset[\"test\"][i][\"sentence\"])\n","    print(tokenized_dataset[\"test\"][i][\"label\"])\n","    print(id2label[predictions[i]])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["83777f5775eb4224ad96e2944bbfb0ad","d8d33756d14d4b48be2e2eef1bca3eb5","a59e7d352dac4510bd998d9171dc8bf0","3429934108c34c16ba22041a18a4b9e5","c0360d653b0342698e4f3e9e74f8c9a3","91c8757761ea4bc79db02ed58ac32e5b","ed49d257d02942a4b01235208c046c44","fc51353af95e45bdb60405dfb28d7d08"]},"executionInfo":{"elapsed":1087,"status":"ok","timestamp":1711466442054,"user":{"displayName":"Đăng Huỳnh Lâm Hải","userId":"13564525226852980347"},"user_tz":-420},"id":"1Pwl2XbGafOL","outputId":"84ba253b-3791-4cc4-ea38-ab643e5f60d8"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"83777f5775eb4224ad96e2944bbfb0ad","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▃▁▆███▇█</td></tr><tr><td>eval/f1_macro</td><td>▅▁▇█████</td></tr><tr><td>eval/f1_micro</td><td>▃▁▆███▇█</td></tr><tr><td>eval/f1_weighted</td><td>▄▁▇█████</td></tr><tr><td>eval/loss</td><td>█▇▂▁▂▃▄▁</td></tr><tr><td>eval/precision_macro</td><td>▂▁▆██▇▇█</td></tr><tr><td>eval/precision_micro</td><td>▃▁▆███▇█</td></tr><tr><td>eval/precision_weighted</td><td>▃▁▆███▇█</td></tr><tr><td>eval/recall_macro</td><td>▆▁▇█████</td></tr><tr><td>eval/recall_micro</td><td>▃▁▆███▇█</td></tr><tr><td>eval/recall_weighted</td><td>▃▁▆███▇█</td></tr><tr><td>eval/runtime</td><td>▂▁▁▁▂▆▆█</td></tr><tr><td>eval/samples_per_second</td><td>▇███▇▃▃▁</td></tr><tr><td>eval/steps_per_second</td><td>▇███▇▃▃▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1_macro</td><td>▁</td></tr><tr><td>test/f1_micro</td><td>▁</td></tr><tr><td>test/f1_weighted</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision_macro</td><td>▁</td></tr><tr><td>test/precision_micro</td><td>▁</td></tr><tr><td>test/precision_weighted</td><td>▁</td></tr><tr><td>test/recall_macro</td><td>▁</td></tr><tr><td>test/recall_micro</td><td>▁</td></tr><tr><td>test/recall_weighted</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▆▄▄▆▆▇█▃▅▁▃▁▁</td></tr><tr><td>train/learning_rate</td><td>█▇▇▆▆▅▄▄▃▃▂▂▁</td></tr><tr><td>train/loss</td><td>█▄▃▃▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.89816</td></tr><tr><td>eval/f1_macro</td><td>0.91224</td></tr><tr><td>eval/f1_micro</td><td>0.89816</td></tr><tr><td>eval/f1_weighted</td><td>0.89711</td></tr><tr><td>eval/loss</td><td>0.27707</td></tr><tr><td>eval/precision_macro</td><td>0.92166</td></tr><tr><td>eval/precision_micro</td><td>0.89816</td></tr><tr><td>eval/precision_weighted</td><td>0.89948</td></tr><tr><td>eval/recall_macro</td><td>0.90563</td></tr><tr><td>eval/recall_micro</td><td>0.89816</td></tr><tr><td>eval/recall_weighted</td><td>0.89816</td></tr><tr><td>eval/runtime</td><td>22.2396</td></tr><tr><td>eval/samples_per_second</td><td>26.934</td></tr><tr><td>eval/steps_per_second</td><td>1.709</td></tr><tr><td>test/accuracy</td><td>0.42171</td></tr><tr><td>test/f1_macro</td><td>0.50623</td></tr><tr><td>test/f1_micro</td><td>0.42171</td></tr><tr><td>test/f1_weighted</td><td>0.42582</td></tr><tr><td>test/loss</td><td>2.56311</td></tr><tr><td>test/precision_macro</td><td>0.51011</td></tr><tr><td>test/precision_micro</td><td>0.42171</td></tr><tr><td>test/precision_weighted</td><td>0.43397</td></tr><tr><td>test/recall_macro</td><td>0.50569</td></tr><tr><td>test/recall_micro</td><td>0.42171</td></tr><tr><td>test/recall_weighted</td><td>0.42171</td></tr><tr><td>test/runtime</td><td>53.0146</td></tr><tr><td>test/samples_per_second</td><td>27.106</td></tr><tr><td>test/steps_per_second</td><td>1.698</td></tr><tr><td>total_flos</td><td>843291718778880.0</td></tr><tr><td>train/epoch</td><td>17.64</td></tr><tr><td>train/global_step</td><td>441</td></tr><tr><td>train/grad_norm</td><td>2.52158</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0819</td></tr><tr><td>train_loss</td><td>0.279</td></tr><tr><td>train_runtime</td><td>3511.8255</td></tr><tr><td>train_samples_per_second</td><td>14.238</td></tr><tr><td>train_steps_per_second</td><td>0.178</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">albert-base-run-vlsp-format1</strong> at: <a href='https://wandb.ai/joatmon/advanced_ai_imdb_dataset/runs/na1mni9d/workspace' target=\"_blank\">https://wandb.ai/joatmon/advanced_ai_imdb_dataset/runs/na1mni9d/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240326_142021-na1mni9d/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.finish()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3429934108c34c16ba22041a18a4b9e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83777f5775eb4224ad96e2944bbfb0ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_d8d33756d14d4b48be2e2eef1bca3eb5","IPY_MODEL_a59e7d352dac4510bd998d9171dc8bf0"],"layout":"IPY_MODEL_3429934108c34c16ba22041a18a4b9e5"}},"91c8757761ea4bc79db02ed58ac32e5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a59e7d352dac4510bd998d9171dc8bf0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed49d257d02942a4b01235208c046c44","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fc51353af95e45bdb60405dfb28d7d08","value":1}},"c0360d653b0342698e4f3e9e74f8c9a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8d33756d14d4b48be2e2eef1bca3eb5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0360d653b0342698e4f3e9e74f8c9a3","placeholder":"​","style":"IPY_MODEL_91c8757761ea4bc79db02ed58ac32e5b","value":"0.025 MB of 0.025 MB uploaded\r"}},"ed49d257d02942a4b01235208c046c44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc51353af95e45bdb60405dfb28d7d08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}